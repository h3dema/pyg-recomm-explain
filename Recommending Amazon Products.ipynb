{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63c222e2",
   "metadata": {},
   "source": [
    "# Recommending Amazon Products using Graph Neural Networks in PyTorch Geometric\n",
    "\n",
    "- Read README.MD to install the dependencies.\n",
    "\n",
    "Based on https://wandb.ai/manan-goel/gnn-recommender/reports/Recommending-Amazon-Products-using-Graph-Neural-Networks-in-PyTorch-Geometric--VmlldzozMTA3MzYw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87f7e74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from IPython.display import IFrame\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric import utils\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "import torch_geometric as pyg\n",
    "\n",
    "from pyvis.network import Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78b162f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain import Explainer, GNNExplainer\n",
    "from torch_geometric.explain import Explainer, PGExplainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b74962",
   "metadata": {},
   "source": [
    "# download and format data\n",
    "\n",
    "- uses data from Snap\n",
    "- ref. : https://snap.stanford.edu/data/amazon0302.html\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6de0af2",
   "metadata": {},
   "source": [
    "We then read all the lines in the file, initialize a numpy array and a list to keep track of the in-degree of each node and the edges respectively.\n",
    "\n",
    "Then all the lines are read one by one and processed: the lines with metadata are ignored and the lines with the start node and end node are processed. The in-degree of the end node is incremented and the edge data is added to edge_index.\n",
    "\n",
    "We use the in-degree of each node and the edge_index to create a PyG graph using the Data class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8964264",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'amazon0302.txt', 'r') as f:\n",
    "    edges = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7639a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit dataset\n",
    "\n",
    "edges = edges[:int(len(edges) * 0.1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a4cc9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123488\n"
     ]
    }
   ],
   "source": [
    "print(len(edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8ea215f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 123488/123488 [00:00<00:00, 279738.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# create graph\n",
    "\n",
    "edge_index = []\n",
    "in_out_degrees = np.zeros((262111, 2))\n",
    "\n",
    "for idx in tqdm(range(len(edges))):\n",
    "    line = edges[idx]\n",
    "    if line.startswith('#'):\n",
    "        # skip comments\n",
    "        continue\n",
    "    start, end = line.strip().split()\n",
    "    start, end = int(start), int(end)\n",
    "    in_out_degrees[end][0] += 1  # in-degree on \"end\"\n",
    "    in_out_degrees[start][1] += 1  # out-degree on \"start\"\n",
    "\n",
    "    edge_index.append([start, end])\n",
    "\n",
    "edge_index = torch.tensor(edge_index).t().contiguous()\n",
    "graph = Data(x=in_out_degrees, edge_index=edge_index)\n",
    "\n",
    "torch.save(graph, 'amazon0302.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee88631",
   "metadata": {},
   "source": [
    "It is incredibly hard and resource intensive to visualize hundreds of thousands of nodes so we sampled the first 100 nodes from the graph using the subgraph utility from PyTorch Geometric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56ae048b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask with the value True for nodes to be retained and False for nodes to be removed\n",
    "mask = np.zeros(graph.x.shape[0])\n",
    "mask[:100] = 1\n",
    "mask = torch.tensor(mask == 1)\n",
    "\n",
    "# Create and save the new smaller graph by sampling nodes according to the a the mask\n",
    "g = Data(x=graph.x[mask], edge_index=utils.subgraph(mask, graph.edge_index)[0])\n",
    "torch.save(g, 'smaller_graph.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c059b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 353/353 [00:00<00:00, 17035.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"750px\"\n",
       "            src=\"graph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1cef1dbb460>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the PyVis network\n",
    "net = Network(height=\"750px\", width=\"100%\", bgcolor=\"#222222\", font_color=\"white\", notebook=True)\n",
    "\n",
    "metadata = dict()\n",
    "# Add the edges from the PyG graph to the PyVis network\n",
    "for e in tqdm(g.edge_index.T):\n",
    "\n",
    "    src = e[0].item()\n",
    "    dst = e[1].item()\n",
    "    if src == 0 or dst == 0:\n",
    "        continue\n",
    "    if src not in metadata:\n",
    "        metadata[src] = {\"title\": str(src), \"categories\": []}\n",
    "    if dst not in metadata:\n",
    "        metadata[dst] = {\"title\": str(dst), \"categories\": []}\n",
    "    src_title = \"Title:\" + metadata[src]['title'] + \"\\n\\n\" + \"Categories:\\n\" + \"\\n\".join(list(metadata[src]['categories'])[:3])\n",
    "    dst_title = \"Title:\" + metadata[dst]['title'] + \"\\n\\n\" + \"Categories:\\n\" + \"\\n\".join(list(metadata[dst]['categories'])[:3])\n",
    "    net.add_node(dst, label=src_title, title=src_title)\n",
    "    net.add_node(src, label=dst_title, title=dst_title)\n",
    "    net.add_edge(src, dst, value=0.1)\n",
    "\n",
    "# Save the PyVis visualisation to a HTML file\n",
    "# AttributeError: 'NoneType' object has no attribute 'render'\n",
    "\n",
    "net.show(\"graph.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dab900",
   "metadata": {},
   "source": [
    "The first thing we need to do is create a train, test and validation split of the edges in the dataset. We start with creating a smaller graph with 20,000 nodes using the same script shown in the previous sections. You can use the following script to randomly split the edges into 3 sections with 5000 edges in the validation and test set each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd595648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 5000 edges in the validation and test sets respectively\n",
    "transform = RandomLinkSplit(num_val=5000, num_test=5000, is_undirected=True, split_labels=True)\n",
    "train_graph, val_graph, test_graph = transform(graph)\n",
    "\n",
    "# Save the splits and save as W&B artifacts\n",
    "torch.save(train_graph, 'train.pt')\n",
    "torch.save(val_graph, 'val.pt')\n",
    "torch.save(test_graph, 'test.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89157d71",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9891673",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, dropout):\n",
    "        super(GNN, self).__init__()\n",
    "        conv_model = pyg.nn.SAGEConv\n",
    "\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(conv_model(input_dim, hidden_dim))\n",
    "        self.dropout = dropout\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "\n",
    "        # Create num_layers GraphSAGE convs\n",
    "        assert (self.num_layers >= 1), 'Number of layers is not >=1'\n",
    "        for l in range(self.num_layers - 1):\n",
    "            self.convs.append(conv_model(hidden_dim, hidden_dim))\n",
    "\n",
    "\n",
    "        # post-message-passing processing \n",
    "        self.post_mp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.Dropout(self.dropout),\n",
    "            nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        x = self.post_mp(x)\n",
    "\n",
    "        # Return final layer of embeddings if specified\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465649e4",
   "metadata": {},
   "source": [
    "# Link Prediction\n",
    "\n",
    "For a pair of nodes, the previous module provides an embedding for both of them. This module is responsible for combining the two embeddings and making a binary prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "213e6a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkPredictor(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(LinkPredictor, self).__init__()\n",
    "\n",
    "        # Create linear layers\n",
    "        self.lins = nn.ModuleList()\n",
    "        self.lins.append(nn.Linear(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(nn.Linear(hidden_channels, hidden_channels))\n",
    "        self.lins.append(nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "\n",
    "    def forward(self, x_i, x_j):\n",
    "        # x_i and x_j are both of shape (E, D)\n",
    "        x = x_i * x_j\n",
    "        for lin in self.lins[:-1]:\n",
    "            x = lin(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lins[-1](x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baa7118",
   "metadata": {},
   "source": [
    "# Training the Model\n",
    "\n",
    "Training a link prediction model brings up a very interesting problem: the dataset we possess is a list of edges in the graph and when you think about it as a binary classification problem, this means we only have positive samples. Hence, there exists a concept called 'negative edges' i.e. edges that do not actually exist in the graph which we consider as negative samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6491b18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, link_predictor, emb, edge_index, pos_train_edge, batch_size, optimizer):\n",
    "    model.train()\n",
    "    link_predictor.train()\n",
    "\n",
    "    train_losses = []\n",
    "\n",
    "    for edge_id in tqdm(pyg.loader.DataLoader(range(pos_train_edge.shape[0]), batch_size, shuffle=True), leave=True):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Run message passing on the inital node embeddings to get updated embeddings\n",
    "        node_emb = model(emb, edge_index)  # (N, d)\n",
    "\n",
    "        # Predict the class probabilities on the batch of positive edges using link_predictor\n",
    "        pos_edge = pos_train_edge[edge_id].T  # (2, B)\n",
    "        pos_pred = link_predictor(node_emb[pos_edge[0]], node_emb[pos_edge[1]])  # (B, )\n",
    "\n",
    "        # Sample negative edges (same number as number of positive edges) and predict class probabilities \n",
    "        neg_edge = utils.negative_sampling(edge_index, num_nodes=emb.shape[0],\n",
    "                                     num_neg_samples=edge_id.shape[0], method='sparse')  # (Ne,2)\n",
    "        neg_pred = link_predictor(node_emb[neg_edge[0]], node_emb[neg_edge[1]])  # (Ne,)\n",
    "\n",
    "        # Compute the corresponding negative log likelihood loss on the positive and negative edges\n",
    "        loss = -torch.log(pos_pred + 1e-15).mean() - torch.log(1 - neg_pred + 1e-15).mean()\n",
    "\n",
    "        # Backpropagate and update parameters\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "    return sum(train_losses) / len(train_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac331c50",
   "metadata": {},
   "source": [
    "### Configure the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12090485",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "optim_wd = 0\n",
    "\n",
    "#epochs = 300\n",
    "epochs = 3\n",
    "\n",
    "hidden_dim = 1024\n",
    "dropout = 0.3\n",
    "num_layers = 2\n",
    "lr = 1e-5\n",
    "node_emb_dim = 2  # 2 features: in/out-degrees\n",
    "batch_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebc0fb4d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_graph = train_graph.to(device)\n",
    "val_graph = val_graph.to(device)\n",
    "\n",
    "model = GNN(node_emb_dim, hidden_dim, hidden_dim, num_layers, dropout).to(device) # the graph neural network that takes all the node embeddings as inputs to message pass and agregate\n",
    "link_predictor = LinkPredictor(hidden_dim, hidden_dim, 1, num_layers + 1, dropout).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(model.parameters()) + list(link_predictor.parameters()),\n",
    "    lr=lr, weight_decay=optim_wd\n",
    ")\n",
    "\n",
    "\n",
    "# train_loss = train(\n",
    "#     model, \n",
    "#     link_predictor, \n",
    "#     torch.tensor(train_graph.x).float().to(device), \n",
    "#     train_graph.edge_index, \n",
    "#     train_graph.pos_edge_label_index.T, \n",
    "#     batch_size, \n",
    "#     optimizer\n",
    "# )\n",
    "\n",
    "# model_name = \"gnn.pt\"\n",
    "# torch.save(model.state_dict(), model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ff0d34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gnn.pt\"\n",
    "if os.path.exists(model_name):\n",
    "    # skip training if it is trained\n",
    "    model.load_state_dict(torch.load(model_name))\n",
    "    model.eval()\n",
    "else:\n",
    "    # train & save\n",
    "    train_loss = train(\n",
    "        model, \n",
    "        link_predictor, \n",
    "        torch.tensor(train_graph.x).float().to(device), \n",
    "        train_graph.edge_index, \n",
    "        train_graph.pos_edge_label_index.T, \n",
    "        batch_size, \n",
    "        optimizer\n",
    "    )\n",
    "    torch.save(model.state_dict(), model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ec73fe",
   "metadata": {},
   "source": [
    "## Explain model using GNNExplainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc3ab07",
   "metadata": {},
   "source": [
    "### you must control below the number of epochs used to train the explainer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6881926",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_explainer = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bee23dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GNNExplainer(epochs=epochs_explainer),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='node',\n",
    "        return_type='log_probs',\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "473829b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated explanations in ['edge_mask', 'node_mask']\n"
     ]
    }
   ],
   "source": [
    "node_index = 10\n",
    "explanation = explainer(\n",
    "    torch.tensor(test_graph.x).float().to(device), \n",
    "    test_graph.edge_index, \n",
    "    index=node_index)\n",
    "print(f'Generated explanations in {explanation.available_explanations}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60e87f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgraph visualization plot has been saved to 'subgraph.pdf'\n"
     ]
    }
   ],
   "source": [
    "path = 'subgraph.pdf'\n",
    "explanation.visualize_graph(path)\n",
    "print(f\"Subgraph visualization plot has been saved to '{path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa62d9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"500\"\n",
       "            src=\"subgraph.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1cef1d69930>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame('subgraph.pdf', width=800, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "731f1493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262111, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_graph.x.shape  # shape[1] ==>> number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49db8d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there is only one feature, will raise\n",
    "# ValueError: Cannot compute feature importance for object-level 'node_mask' (got shape torch.Size([262111, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d241982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance plot has been saved to 'feature_importance.png'\n"
     ]
    }
   ],
   "source": [
    "path = 'feature_importance.png'\n",
    "explanation.visualize_feature_importance(path, top_k=10)\n",
    "print(f\"Feature importance plot has been saved to '{path}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992352bf",
   "metadata": {},
   "source": [
    "<img src=\"./feature_importance.png\" alt=\"Computed feature importance\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1bfce110",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_graph_path = 'graph_feature_importance.png'\n",
    "explanation.visualize_graph(feat_graph_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd1de7c",
   "metadata": {},
   "source": [
    "<img src=\"./graph_feature_importance.png\" alt=\"Computed feature importance\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702f8bab",
   "metadata": {},
   "source": [
    "## Explain model using PGExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07d1ba82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.explain.config import ModelConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f72a134",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=PGExplainer(epochs=epochs_explainer, lr=0.003),\n",
    "    explanation_type='phenomenon',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='node',\n",
    "        return_type='log_probs',\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9acc432e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader.node_loader import NodeLoader\n",
    "from torch_geometric.loader.neighbor_loader import NeighborLoader\n",
    "from torch_geometric.sampler.base import NodeSamplerInput\n",
    "from torch_geometric.sampler.neighbor_sampler import NeighborSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ccc9b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to train with batches, otherwise raises memory errors\n",
    "\n",
    "test_dataloader = NeighborLoader(\n",
    "    train_graph,\n",
    "    num_neighbors=[50] * 2,\n",
    "    batch_size=100,\n",
    "    input_nodes=[1 for _ in range(train_graph.x.shape[0])],\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33be2829",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9855c23d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[116, 2], edge_index=[2, 423], pos_edge_label=[49041], pos_edge_label_index=[2, 49041], neg_edge_label=[49041], neg_edge_label_index=[2, 49041], n_id=[116], e_id=[423], input_id=[100], batch_size=100)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0cffb81e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                        | 0/10 [00:00<?, ?it/s]C:\\Users\\henri\\AppData\\Local\\Temp\\ipykernel_15988\\2590705534.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(data.x).float().to(device),\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 10/10 [4:48:18<00:00, 1729.81s/it]\n"
     ]
    }
   ],
   "source": [
    "# Train against a variety of node-level or graph-level predictions:\n",
    "\n",
    "# only positive examples\n",
    "target = torch.tensor([1 for _ in range(N)])  \n",
    "\n",
    "for epoch in tqdm(range(epochs_explainer)):\n",
    "    for data in test_dataloader:\n",
    "        N = data.x.shape[0]\n",
    "        indeces = np.random.choice(list(range(N)), replace=False, size=int(.1 * N))  # train only on 10%\n",
    "        # do I need to guarantee that `node_index` is in indeces??\n",
    "        \n",
    "        for index in indeces:  # Indices to train against.\n",
    "            # print(epoch, index, data.x.shape, data.edge_index.shape)\n",
    "            loss = explainer.algorithm.train(\n",
    "                epoch, \n",
    "                model, \n",
    "                torch.tensor(data.x).float().to(device), \n",
    "                data.edge_index,\n",
    "                target=target[:data.x.shape[0]], \n",
    "                index=[index],\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e1101162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the final explanations:\n",
    "explanation_pge = explainer(\n",
    "    torch.tensor(test_graph.x).float().to(device), \n",
    "    test_graph.edge_index, \n",
    "    index=node_index,\n",
    "    target=target[:test_graph.x.shape[0]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3e9e44e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgraph visualization plot has been saved to 'pge-subgraph.pdf'\n"
     ]
    }
   ],
   "source": [
    "path_pge = 'pge-subgraph.pdf'\n",
    "explanation_pge.visualize_graph(path_pge)\n",
    "print(f\"Subgraph visualization plot has been saved to '{path_pge}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "46a6af43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"500\"\n",
       "            src=\"pge-subgraph.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1cefee23910>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame('pge-subgraph.pdf', width=800, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50f951b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c562e7ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e539191b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
